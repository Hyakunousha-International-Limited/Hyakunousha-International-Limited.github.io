{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Association Rules Mining documentation! Description A project for mining association rules in historical transaction data. The model can be configured with the config/model.toml in details. Commands Running the model consists of 2 parts: --gen_rules indicates the procedure of mining the association rules. --nodes_values indicates the procedure of calculating the node values. The model will generatet the association rules first. After that, the model can generate the node values of individual nodes. python main.py --gen_rules --nodes_values --topic HKD12 The --topic argument is set for different scenarios. So far, possible options include HKD12 for the scenario of 12 HKD omushibi promotion; and Cluster for studying the association rules of in the purchasing history of customers of different tiers.","title":"Home"},{"location":"#association-rules-mining-documentation","text":"","title":"Association Rules Mining documentation!"},{"location":"#description","text":"A project for mining association rules in historical transaction data. The model can be configured with the config/model.toml in details.","title":"Description"},{"location":"#commands","text":"Running the model consists of 2 parts: --gen_rules indicates the procedure of mining the association rules. --nodes_values indicates the procedure of calculating the node values. The model will generatet the association rules first. After that, the model can generate the node values of individual nodes. python main.py --gen_rules --nodes_values --topic HKD12 The --topic argument is set for different scenarios. So far, possible options include HKD12 for the scenario of 12 HKD omushibi promotion; and Cluster for studying the association rules of in the purchasing history of customers of different tiers.","title":"Commands"},{"location":"developer-guide/","text":"Developer Guide","title":"Developer Guide"},{"location":"developer-guide/#developer-guide","text":"","title":"Developer Guide"},{"location":"fundamental_knowledge/","text":"Fundamental Knowledge Association Rules Mining Association Rules Mining aims at finding interesting relations between variables in large databases. Specifically, a relations is denoted as A\\rightarrow B meaning if A (Antecendent) occurs then B (Consequence) is more likely to occur. To identify the \"interestingness\" of a relation, there are 3 mostly used metrics: Support , Confidence and Lift . \\begin{aligned} \\text{Support}( A\\rightarrow B) & = P(A\\cap B) \\nonumber\\\\ \\text{Confidence}( A\\rightarrow B) &= P(B|A) \\nonumber\\\\ \\text{Lift}( A\\rightarrow B) &= \\frac{P(B|A)}{P(B)} \\nonumber \\end{aligned} It is easy to understand Support and Confidence , which are simply the probability of the co-occurence of the A and B , and the conditional probability of B given A . Lift , means how much of the probability of B is \"lifted\" when A occurs. There are also 2 commonly used metrics to evaluate the interestingness of a relationship, namely Improvement and Conviction \\begin{aligned} \\text{Improvement}( A\\rightarrow B) & = P(B|A) - P(B) \\nonumber\\\\ \\text{Conviction}( A\\rightarrow B) &= \\frac{1-P(B)}{1-P(B|A)} = \\frac{P(\\text{not } B)}{P(\\text{not } B|A)} \\nonumber \\end{aligned} Improvement is very similar to Lift except the fact that Improvement compares the probility of B with and without knowing A by taking \"difference\" instead of \"ratio\". Conviction , on the other hand, compares how the probability of not B when A occurs. All the metrics metioned above only considered how the probabilities changes when knowing A occurs, and not considering the situation when knowing A not occurs. Baos et. al. (2022) proposed to measure the interetingness of the rules using Bi-Metrics. \\begin{align} \\text{Bi-Confidence}(A\\rightarrow B) &= P(B|A) - P(B|\\text{not }A)\\nonumber\\\\ \\text{Bi-Lift}( A\\rightarrow B) &= \\frac{\\text{Lift}( A\\rightarrow B)}{\\text{Lift}( \\text{not }A\\rightarrow B)} = \\frac{P(A\\cap B)P(\\text{not }A)}{P(\\text{not }A\\cap B)P(A)}\\nonumber\\\\ \\text{Bi-Improvement}( A\\rightarrow B) & = [P(B|A) - P(B)]\\frac{P(A)}{P(\\text{not }A)} \\nonumber \\end{align} Leverage and Chi-Square value can be used for dependency evaluation. Specifically, \\begin{align} \\text{Leverage}(A\\rightarrow B) &= P(A\\cap B) - P(A)P(B) \\nonumber\\\\ \\chi^2(A\\rightarrow B) &= \\sqrt{n}\\frac{P(B|A)-P(B)}{\\sqrt{P(B)(1-P(B))}} \\nonumber\\\\ \\end{align} In case when A and B are independent, P(A\\cap B) = P(A)P(B) , and Leverage = 0. Hence Leverage measures in what extent A , B are independent. For a 2x2 contingency table of 1 degree of freedom, \\chi^2 > 3.84 in order to reject the null hypothesis (with 0.05 significance level). Node Values Theoretically, value of a node can be decomposed into 3 parts: the incoming value, the outgoing value and the intrinsic value. Considering the example of A\\rightarrow B , and B\\rightarrow C Incoming Value of node B: the value (sales, or quantity sold) of B that is caused by A . Outgoing Value of node B: the value (sales, or quantity sold) of C that is induced by B . Intrinsic Value of node B: the total value (sales, or quantity sold) of B that is not caused by A .","title":"Fundamental Knowledges"},{"location":"fundamental_knowledge/#fundamental-knowledge","text":"","title":"Fundamental Knowledge"},{"location":"fundamental_knowledge/#association-rules-mining","text":"Association Rules Mining aims at finding interesting relations between variables in large databases. Specifically, a relations is denoted as A\\rightarrow B meaning if A (Antecendent) occurs then B (Consequence) is more likely to occur. To identify the \"interestingness\" of a relation, there are 3 mostly used metrics: Support , Confidence and Lift . \\begin{aligned} \\text{Support}( A\\rightarrow B) & = P(A\\cap B) \\nonumber\\\\ \\text{Confidence}( A\\rightarrow B) &= P(B|A) \\nonumber\\\\ \\text{Lift}( A\\rightarrow B) &= \\frac{P(B|A)}{P(B)} \\nonumber \\end{aligned} It is easy to understand Support and Confidence , which are simply the probability of the co-occurence of the A and B , and the conditional probability of B given A . Lift , means how much of the probability of B is \"lifted\" when A occurs. There are also 2 commonly used metrics to evaluate the interestingness of a relationship, namely Improvement and Conviction \\begin{aligned} \\text{Improvement}( A\\rightarrow B) & = P(B|A) - P(B) \\nonumber\\\\ \\text{Conviction}( A\\rightarrow B) &= \\frac{1-P(B)}{1-P(B|A)} = \\frac{P(\\text{not } B)}{P(\\text{not } B|A)} \\nonumber \\end{aligned} Improvement is very similar to Lift except the fact that Improvement compares the probility of B with and without knowing A by taking \"difference\" instead of \"ratio\". Conviction , on the other hand, compares how the probability of not B when A occurs. All the metrics metioned above only considered how the probabilities changes when knowing A occurs, and not considering the situation when knowing A not occurs. Baos et. al. (2022) proposed to measure the interetingness of the rules using Bi-Metrics. \\begin{align} \\text{Bi-Confidence}(A\\rightarrow B) &= P(B|A) - P(B|\\text{not }A)\\nonumber\\\\ \\text{Bi-Lift}( A\\rightarrow B) &= \\frac{\\text{Lift}( A\\rightarrow B)}{\\text{Lift}( \\text{not }A\\rightarrow B)} = \\frac{P(A\\cap B)P(\\text{not }A)}{P(\\text{not }A\\cap B)P(A)}\\nonumber\\\\ \\text{Bi-Improvement}( A\\rightarrow B) & = [P(B|A) - P(B)]\\frac{P(A)}{P(\\text{not }A)} \\nonumber \\end{align} Leverage and Chi-Square value can be used for dependency evaluation. Specifically, \\begin{align} \\text{Leverage}(A\\rightarrow B) &= P(A\\cap B) - P(A)P(B) \\nonumber\\\\ \\chi^2(A\\rightarrow B) &= \\sqrt{n}\\frac{P(B|A)-P(B)}{\\sqrt{P(B)(1-P(B))}} \\nonumber\\\\ \\end{align} In case when A and B are independent, P(A\\cap B) = P(A)P(B) , and Leverage = 0. Hence Leverage measures in what extent A , B are independent. For a 2x2 contingency table of 1 degree of freedom, \\chi^2 > 3.84 in order to reject the null hypothesis (with 0.05 significance level).","title":"Association Rules Mining"},{"location":"fundamental_knowledge/#node-values","text":"Theoretically, value of a node can be decomposed into 3 parts: the incoming value, the outgoing value and the intrinsic value. Considering the example of A\\rightarrow B , and B\\rightarrow C Incoming Value of node B: the value (sales, or quantity sold) of B that is caused by A . Outgoing Value of node B: the value (sales, or quantity sold) of C that is induced by B . Intrinsic Value of node B: the total value (sales, or quantity sold) of B that is not caused by A .","title":"Node Values"},{"location":"getting-started/","text":"Getting started This is where you describe how to get set up on a clean install, including the commands necessary to get the raw data (using the sync_data_from_s3 command, for example), and then how to make the cleaned, final data sets.","title":"Getting started"},{"location":"getting-started/#getting-started","text":"This is where you describe how to get set up on a clean install, including the commands necessary to get the raw data (using the sync_data_from_s3 command, for example), and then how to make the cleaned, final data sets.","title":"Getting started"},{"location":"user-guide/","text":"User Guide Activate the Virtual Environment User should create and activate the virtual environment defined in environemnt.yml . To create the virtual environment, conda env create -f environment.yml After creating the virtual environment, activate it before running the model. The name of the environment just created should be arules_env_refactor . conda activate <name_of_the_environment> Run the Model After activating the conda environment, the model can be excuted by running the main.py script. python main.py --gen_rules --nodes_values --topic HKD12 ..... Using the Configuration Files The project can be configured in detailed using two config files: the config/model.toml and config/project.toml . Inside the config/model.toml , [Train] [Args] # [\"HANA-MUSUBI\", \"OMUSUBI\"] brand = [\"HANA-MUSUBI\"] # [True, False] licensed = [] # [\"Breakfast\", \"Lunch\", \"TeaTime\", \"Dinner\"] meal = [\"Breakfast\", \"Lunch\", \"TeaTime\", \"Dinner\"] # [\"Top\", \"Core\", \"TopHigh\", \"TopLow\", \"CoreHigh\", \"CoreLow\"] tier = [] # [\"SUN\", \"SAT\", \"WKD\"] daytype = [\"SUN\", \"SAT\", \"WKD\"] # [\"P1\", \"P2\", \"False\"] promotion = [\"P1\", \"P2\", \"False\"] # [\"D\", \"ND\"], # TODO Allow discount name input. discount = [true, false] [Hyperparams] [Architectures] [Validate] [Test] Inside the config/project.toml , [Dirs] RawDir = 'data/raw' ProcessedDir = 'data/processed' ExternalDir = 'data/external' InterimDir = 'data/interim' ModelDir = 'models' OutputDir = 'output' LoggerDir = 'logger' [DatName]","title":"User Guide"},{"location":"user-guide/#user-guide","text":"","title":"User Guide"},{"location":"user-guide/#activate-the-virtual-environment","text":"User should create and activate the virtual environment defined in environemnt.yml . To create the virtual environment, conda env create -f environment.yml After creating the virtual environment, activate it before running the model. The name of the environment just created should be arules_env_refactor . conda activate <name_of_the_environment>","title":"Activate the Virtual Environment"},{"location":"user-guide/#run-the-model","text":"After activating the conda environment, the model can be excuted by running the main.py script. python main.py --gen_rules --nodes_values --topic HKD12 .....","title":"Run the Model"},{"location":"user-guide/#using-the-configuration-files","text":"The project can be configured in detailed using two config files: the config/model.toml and config/project.toml . Inside the config/model.toml , [Train] [Args] # [\"HANA-MUSUBI\", \"OMUSUBI\"] brand = [\"HANA-MUSUBI\"] # [True, False] licensed = [] # [\"Breakfast\", \"Lunch\", \"TeaTime\", \"Dinner\"] meal = [\"Breakfast\", \"Lunch\", \"TeaTime\", \"Dinner\"] # [\"Top\", \"Core\", \"TopHigh\", \"TopLow\", \"CoreHigh\", \"CoreLow\"] tier = [] # [\"SUN\", \"SAT\", \"WKD\"] daytype = [\"SUN\", \"SAT\", \"WKD\"] # [\"P1\", \"P2\", \"False\"] promotion = [\"P1\", \"P2\", \"False\"] # [\"D\", \"ND\"], # TODO Allow discount name input. discount = [true, false] [Hyperparams] [Architectures] [Validate] [Test] Inside the config/project.toml , [Dirs] RawDir = 'data/raw' ProcessedDir = 'data/processed' ExternalDir = 'data/external' InterimDir = 'data/interim' ModelDir = 'models' OutputDir = 'output' LoggerDir = 'logger' [DatName]","title":"Using the Configuration Files"}]}